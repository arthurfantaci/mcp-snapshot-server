# MCP Snapshot Server

A production-ready Model Context Protocol (MCP) server that generates comprehensive Customer Success Snapshots from Zoom meeting transcripts using Claude AI.

[![Tests](https://img.shields.io/badge/tests-111%20passing-brightgreen)]()
[![Python](https://img.shields.io/badge/python-3.10%2B-blue)]()
[![License](https://img.shields.io/badge/license-MIT-blue)]()

## Overview

MCP Snapshot Server is a production-ready Model Context Protocol (MCP) server that transforms Zoom meeting transcripts into actionable customer success intelligence. It provides two powerful modes of operation:

1. **Ad-Hoc Transcript Analysis** - Query Zoom transcripts directly for quick insights without generating full documentation
2. **Comprehensive Documentation** - Generate professional 11-section Customer Success Snapshots automatically

### What Makes This Unique

**üéØ Instant Transcript Access**
- Fetch Zoom transcripts and query them immediately in conversation
- Ask questions like "What pain points were discussed?" or "Who were the key stakeholders?"
- No need to generate full reports for simple questions‚Äîget answers in seconds

**üìã Full Documentation When Needed**
- Generate comprehensive 11-section snapshots for formal case studies
- Multi-agent AI system ensures accuracy and completeness
- Confidence scoring (0.0-1.0) for each section with quality validation
- Auto-validation catches inconsistencies across sections

**üîó Seamless Zoom Integration**
- Direct OAuth 2.0 integration with Zoom's API
- List, search, and fetch transcripts without leaving your workflow
- Smart caching (15-min TTL) minimizes API calls and speeds up access
- Handles all authentication and error cases automatically

**üèóÔ∏è Enterprise-Grade Architecture**
- All 6 MCP primitives fully implemented (Tools, Resources, Prompts, Sampling, Elicitation, Logging)
- 111 passing tests with comprehensive error handling
- Hybrid NLP + AI approach: spaCy/NLTK for entity extraction, Claude for deep analysis
- Structured JSON logging with full traceability for debugging and auditing

### Why Users Choose This

**For Customer Success Managers:**
- Quickly review meeting transcripts to identify action items and concerns
- Generate professional case studies for marketing and sales enablement
- Track customer engagement patterns across multiple touchpoints

**For Sales Teams:**
- Extract key insights from discovery calls without manual note-taking
- Identify decision-makers, pain points, and buying signals automatically
- Create compelling customer stories backed by actual conversation data

**For Product Teams:**
- Analyze customer feedback patterns across many meetings
- Identify common feature requests and pain points at scale
- Generate data-driven insights from qualitative conversations

### Technical Highlights

‚úÖ **Tools** - 4 specialized tools for Zoom integration and snapshot generation
‚úÖ **Resources** - Transcripts, snapshots, sections, and field definitions exposed as MCP Resources
‚úÖ **Prompts** - 11 section-specific prompts + field elicitation for completeness
‚úÖ **Sampling** - Integrated Claude AI with retry logic and confidence scoring
‚úÖ **Elicitation** - Interactive collection of missing field information
‚úÖ **Logging** - Structured JSON logging with context and full traceability

## Table of Contents

- [Quick Start](#quick-start)
- [Usage Examples](#usage-examples)
- [Documentation](#documentation)
- [Architecture](#architecture)
- [Development](#development)
- [Contributing](#contributing)

## Quick Start

### Prerequisites

- **Python 3.10+** (3.11 or 3.12 recommended)
- **uv** package manager ([install](https://docs.astral.sh/uv/))
- **Anthropic API key** with Claude access
- **Zoom OAuth credentials** (Account ID, Client ID, Client Secret) - See [docs/ZOOM_SETUP.md](docs/ZOOM_SETUP.md)
  - ‚ö†Ô∏è **Important**: Your Zoom app must have the `cloud_recording:read:list_recording_files` scopes enabled

### Installation

```bash
# 1. Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. Clone repository
git clone https://github.com/your-org/mcp-snapshot-server.git
cd mcp-snapshot-server

# 3. Install dependencies
uv sync --all-extras

# 4. Download NLP models
uv run python -m spacy download en_core_web_sm
uv run python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# 5. Configure credentials
cp .env.example .env
# Edit .env and add:
#   - Your Anthropic API key (LLM_ANTHROPIC_API_KEY)
#   - Your Zoom credentials (ZOOM_ACCOUNT_ID, ZOOM_CLIENT_ID, ZOOM_CLIENT_SECRET)
#
# See docs/ZOOM_SETUP.md for detailed Zoom setup instructions
```

### Run Tests

```bash
# Run all tests (should see 107/108 passing)
uv run pytest tests/ -v

# Run specific test suites
uv run pytest tests/test_server.py -v      # MCP server tests
uv run pytest tests/test_agents/ -v        # Agent tests
```

## Usage Examples

### Basic Zoom Workflow

The server provides a streamlined workflow for processing Zoom transcripts:

```
1. List available Zoom recordings
   ‚Üì
2. Download a transcript from Zoom
   ‚Üì
3. Generate Customer Success Snapshot
```

Or use the one-step convenience tool to do steps 2-3 automatically!

### With Claude Desktop

1. **Find your uv installation path** (Claude Desktop needs the full path):
   ```bash
   which uv
   ```

2. **Add to Claude Desktop config** (`~/Library/Application Support/Claude/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "mcp-snapshot-server": {
      "command": "/Users/yourname/.local/bin/uv",
      "args": [
        "--directory",
        "/absolute/path/to/mcp-snapshot-server",
        "run",
        "mcp-snapshot-server"
      ],
      "env": {
        "LLM_ANTHROPIC_API_KEY": "${ANTHROPIC_API_KEY}",
        "ZOOM_ACCOUNT_ID": "${ZOOM_ACCOUNT_ID}",
        "ZOOM_CLIENT_ID": "${ZOOM_CLIENT_ID}",
        "ZOOM_CLIENT_SECRET": "${ZOOM_CLIENT_SECRET}"
      }
    }
  }
}
```

   **Important:** Replace `/Users/yourname/.local/bin/uv` with the output from step 1.

3. **Restart Claude Desktop**

4. **Use in conversation**:

```
# List my recent Zoom recordings with transcripts
list_zoom_recordings

# Search for specific recordings
list_zoom_recordings with topic containing "customer"

# Fetch and generate snapshot in one step
generate_snapshot_from_zoom for meeting ID 123456789

# OR: Fetch transcript to query it directly
fetch_zoom_transcript meeting_id="123456789"
# Returns: transcript://abc789

# Now ask questions about it
What pain points were discussed in transcript://abc789?
Who were the key attendees in that meeting?
```

See [CLAUDE_DESKTOP.md](CLAUDE_DESKTOP.md) for detailed integration guide.

### Programmatic Usage

```python
from mcp_snapshot_server.server import SnapshotMCPServer

# Initialize server
server = SnapshotMCPServer()

# List Zoom recordings
recordings = await server._call_tool(
    "list_zoom_recordings",
    {
        "from_date": "2024-11-01",
        "to_date": "2024-11-24",
        "search_query": "customer"
    }
)

# Fetch and cache specific transcript
transcript = await server._call_tool(
    "fetch_zoom_transcript",
    {"meeting_id": "123456789"}
)

# Generate snapshot from cached transcript
result = await server._call_tool(
    "generate_customer_snapshot",
    {
        "transcript_uri": "transcript://abc123",  # From fetch step
        "output_format": "json"  # or "markdown"
    }
)

# OR: One-step download + generate
result = await server._call_tool(
    "generate_snapshot_from_zoom",
    {
        "meeting_id": "123456789",
        "output_format": "markdown"
    }
)

# Access specific section via Resources
section = await server._read_resource(
    "snapshot://meeting/section/executive_summary"
)

# Get elicitation prompt for missing data via Prompts
prompt = await server._get_prompt(
    "elicit_missing_field",
    {
        "field_name": "roi_percentage",
        "section_name": "Financial Impact"
    }
)
```

### Command Line

```bash
# Run the MCP server
uv run mcp-snapshot-server

# Or use Python module
uv run python -m mcp_snapshot_server
```

## Documentation

### Essential Guides
- **[docs/ZOOM_SETUP.md](docs/ZOOM_SETUP.md)** - ‚≠ê Zoom OAuth setup (required for Zoom integration)
- **[CLAUDE_DESKTOP.md](CLAUDE_DESKTOP.md)** - Claude Desktop integration and configuration
- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Production deployment guide
- **[SECURITY.md](SECURITY.md)** - Security best practices and considerations
- **[API_REFERENCE.md](API_REFERENCE.md)** - Complete API reference and examples

## Architecture

### Two Usage Modes

**Mode 1: Ad-Hoc Transcript Queries (Fast)**
```
Zoom Meeting ID
  ‚Üì
fetch_zoom_transcript ‚Üí Fetch & cache transcript
  ‚Üì
transcript://abc789 (Exposed as MCP Resource)
  ‚Üì
Query directly: "What were the pain points discussed?"
  ‚Üì
Claude analyzes transcript text ‚Üí Instant answer
```

**Mode 2: Full Snapshot Generation (Comprehensive)**
```
Zoom Meeting ID
  ‚Üì
fetch_zoom_transcript OR generate_snapshot_from_zoom
  ‚Üì
Cache Transcript (transcript://id)
  ‚Üì
Parse Transcript ‚Üí Extract structure, speakers, timing
  ‚Üì
Analysis Agent ‚Üí NLP entity extraction + topic identification
  ‚Üì
11 Section Generator Agents ‚Üí Specialized content for each section
  ‚Üì
Validation Agent ‚Üí Cross-section consistency + quality checks
  ‚Üì
Executive Summary Generator ‚Üí Synthesize final overview
  ‚Üì
Complete 11-Section Snapshot with confidence scores
```

### Available Tools

1. **`list_zoom_recordings`** - List and search Zoom recordings with transcripts
2. **`fetch_zoom_transcript`** - Fetch & cache transcript (returns full text + URI)
3. **`generate_customer_snapshot`** - Generate full snapshot from cached transcript URI
4. **`generate_snapshot_from_zoom`** - One-step: fetch + generate full snapshot

### Transcript Querying (MCP Resources)

Fetched transcripts are exposed as MCP Resources with full text content, allowing immediate analysis:

```
# Fetch transcript (returns full content immediately)
fetch_zoom_transcript meeting_id="123456789"
‚Üí Returns transcript://abc789 with full text

# Ask questions directly - no snapshot generation needed
"What pain points were discussed in this meeting?"
"Who were the key stakeholders mentioned?"
"Summarize the action items from this conversation"
"What technical requirements were identified?"
```

The transcript content is available both:
- **Immediately** in the tool response for instant access
- **As an MCP Resource** for structured programmatic access

### Multi-Agent System

```
OrchestrationAgent
‚îú‚îÄ‚îÄ AnalysisAgent (NLP + LLM hybrid analysis)
‚îú‚îÄ‚îÄ SectionGeneratorAgents √ó 11 (specialized per section)
‚îî‚îÄ‚îÄ ValidationAgent (consistency + quality checks)
```

### Technology Stack

- **Language**: Python 3.10+
- **Package Manager**: uv (10-100x faster than pip)
- **Linting**: ruff (Rust-based, replaces black + isort + flake8)
- **Type Checking**: mypy with strict mode
- **Testing**: pytest with 111 passing tests
- **LLM**: Anthropic Claude (Sonnet 4.5)
- **NLP**: spaCy + NLTK for entity extraction
- **API Integration**: Zoom OAuth 2.0 Server-to-Server
- **Protocol**: Model Context Protocol (MCP) - All 6 primitives
- **Validation**: Pydantic V2 for data validation and configuration

### The 11 Sections

1. **Customer Information** - Company details, contacts, industry
2. **Background** - Initial problems and challenges
3. **Solution** - Implemented products/services
4. **Engagement Details** - Timeline, milestones, team
5. **Results and Achievements** - Quantifiable improvements
6. **Adoption and Usage** - User engagement metrics
7. **Financial Impact** - ROI, cost savings, revenue
8. **Long-Term Impact** - Strategic benefits
9. **Visuals** - Suggested charts and graphics
10. **Additional Commentary** - Unique insights
11. **Executive Summary** - High-level overview

## Development

### Setup Development Environment

```bash
# Install dependencies with dev tools
uv sync --all-extras

# Install pre-commit hooks (optional)
pre-commit install
```

### Code Quality

```bash
# Format code
uv run ruff format .

# Lint and auto-fix
uv run ruff check --fix .

# Type check
uv run mypy src/

# Run all quality checks
uv run ruff format . && uv run ruff check --fix . && uv run mypy src/
```

### Testing

```bash
# Run all tests
uv run pytest tests/ -v

# Run with coverage
uv run pytest tests/ --cov=mcp_snapshot_server --cov-report=html

# Run specific test file
uv run pytest tests/test_server.py -v

# Run tests matching pattern
uv run pytest tests/ -k "test_snapshot" -v
```

### Project Structure

```
mcp-snapshot-server/
‚îú‚îÄ‚îÄ src/mcp_snapshot_server/
‚îÇ   ‚îú‚îÄ‚îÄ server.py              # Main MCP server (all 6 primitives)
‚îÇ   ‚îú‚îÄ‚îÄ __main__.py            # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ agents/                # Multi-agent system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py           # Abstract base agent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py       # Transcript analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section_generator.py  # Section generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator.py      # Validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py   # Workflow orchestration
‚îÇ   ‚îú‚îÄ‚îÄ prompts/               # Templates and definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system_prompts.py # Agent system prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section_prompts.py# Section templates
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ field_definitions.py  # Elicitable fields
‚îÇ   ‚îú‚îÄ‚îÄ tools/                 # VTT and NLP utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcript_utils.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nlp_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                 # Infrastructure
‚îÇ       ‚îú‚îÄ‚îÄ config.py         # Pydantic settings
‚îÇ       ‚îú‚îÄ‚îÄ logging_config.py # Structured logging
‚îÇ       ‚îú‚îÄ‚îÄ errors.py         # Error handling
‚îÇ       ‚îî‚îÄ‚îÄ sampling.py       # LLM integration
‚îú‚îÄ‚îÄ tests/                     # 98 comprehensive tests
‚îÇ   ‚îú‚îÄ‚îÄ test_server.py        # MCP server tests (27)
‚îÇ   ‚îú‚îÄ‚îÄ test_agents/          # Agent tests (29)
‚îÇ   ‚îú‚îÄ‚îÄ test_tools/           # Tool tests (17)
‚îÇ   ‚îú‚îÄ‚îÄ test_utils/           # Utility tests (25)
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/             # Test fixtures (VTT files)
‚îú‚îÄ‚îÄ docs/                      # Project documentation
‚îÇ   ‚îú‚îÄ‚îÄ MCP_Server_Project_Specification.md
‚îÇ   ‚îú‚îÄ‚îÄ All_Prompt_Details.txt
‚îÇ   ‚îú‚îÄ‚îÄ System_Prompt_Customer_Success_Snapshot.txt
‚îÇ   ‚îî‚îÄ‚îÄ Quest_Enterprises_Kickoff_Transcript_Summary.md
‚îú‚îÄ‚îÄ .env.example              # Environment template
‚îú‚îÄ‚îÄ pyproject.toml            # Project config
‚îî‚îÄ‚îÄ README.md                 # This file
```

## Configuration

### Environment Variables

```bash
# Required
LLM_ANTHROPIC_API_KEY=sk-ant-your-key-here

# Optional - LLM Settings
LLM_MODEL=claude-3-5-sonnet-20241022
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4000

# Optional - Workflow
WORKFLOW_PARALLEL_SECTION_GENERATION=false
WORKFLOW_MIN_CONFIDENCE_THRESHOLD=0.5

# Optional - NLP
NLP_SPACY_MODEL=en_core_web_sm
NLP_MAX_ENTITIES_PER_TYPE=10

# Optional - Logging
LOG_LEVEL=INFO
```

See `.env.example` for all configuration options.

## Production Deployment

For production deployment:
1. Review [DEPLOYMENT.md](DEPLOYMENT.md) for deployment options
2. Review [SECURITY.md](SECURITY.md) for security best practices
3. Set up monitoring and logging
4. Configure rate limiting
5. Implement backup strategy

### Quick Production Setup

```bash
# Using systemd (Linux)
sudo cp deploy/mcp-snapshot-server.service /etc/systemd/system/
sudo systemctl enable mcp-snapshot-server
sudo systemctl start mcp-snapshot-server

# Using Docker
docker build -t mcp-snapshot-server .
docker run -e LLM_ANTHROPIC_API_KEY=your-key mcp-snapshot-server
```

## Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests (`uv run pytest tests/ -v`)
5. Run code quality checks (`uv run ruff format . && uv run ruff check --fix .`)
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

### Development Guidelines

- Write tests for new features
- Maintain test coverage above 80%
- Follow existing code style (ruff enforces this)
- Update documentation for user-facing changes
- Add type hints (mypy enforces this)

## Troubleshooting

### Claude Desktop: "spawn uv ENOENT" Error

This is the most common installation issue. Claude Desktop cannot find the `uv` command.

**Solution:** Use the full path to `uv` in your config:
```bash
# 1. Find uv path
which uv

# 2. Update claude_desktop_config.json with the full path:
# "command": "/Users/yourname/.local/bin/uv"  ‚Üê Use your actual path
```

See [CLAUDE_DESKTOP.md](CLAUDE_DESKTOP.md#troubleshooting) for detailed troubleshooting.

### Server Won't Start

```bash
# Check Python version
python --version  # Should be 3.10+

# Verify dependencies
uv sync

# Check API key
echo $LLM_ANTHROPIC_API_KEY

# View logs
journalctl -u mcp-snapshot-server -f
```

### API Errors

- Verify API key is valid
- Check Anthropic API status
- Review rate limits
- Check network connectivity

### Poor Quality Snapshots

- Ensure transcript has clear speaker labels
- Check transcript quality (clear, complete content)
- Adjust `LLM_TEMPERATURE` (lower = more conservative)
- Review section prompts for customization

### Tests Failing

```bash
# Clean and reinstall
rm -rf .venv
uv sync --all-extras

# Download models again
uv run python -m spacy download en_core_web_sm

# Run tests
uv run pytest tests/ -v
```

## License

MIT License - see [LICENSE](LICENSE) file for details.

## Support

- **Documentation**: Check docs in this repository
- **Issues**: Open a [GitHub Issue](https://github.com/your-org/mcp-snapshot-server/issues)
- **Security**: See [SECURITY.md](SECURITY.md) for reporting vulnerabilities

## Changelog

### v1.0.0 (Current)
- ‚úÖ All 6 MCP primitives implemented
- ‚úÖ 11-section snapshot generation
- ‚úÖ Multi-agent orchestration
- ‚úÖ Claude Desktop integration
- ‚úÖ 98/98 tests passing
- ‚úÖ Production-ready documentation

---

**Built with ‚ù§Ô∏è using Claude AI**
